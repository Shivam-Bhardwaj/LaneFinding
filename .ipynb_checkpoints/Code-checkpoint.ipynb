{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "The following project is the first project of the Udacity- Self-Driving Car Engineer Nanodegree. The aim of this project was to implement a pipeline to detect lanes on the road. The pipeline was first tested on a series of images and then on a video stream. \n",
    "\n",
    "The following pipeline was used to obtain a satisfactory and annotated video of lanes on an highway.\n",
    "\n",
    "    1. Image is read using OpenCV\n",
    "    2. The image is converted in Grayscale\n",
    "    3. Gausian Filter is applied on the grayscale image.\n",
    "    4. Canny edge detection is performed on the image.\n",
    "    5. A region of interest is selected and a mask is created from it.\n",
    "    6. Using hough transform lines are detected on the image.\n",
    "    7. The lines obtained are interpolated to mark the lanes properly.\n",
    "    8. The pipeline for single image is applied on a video which is just series of images.\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"examples/line-segments-example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> This is the result without interpolation of the lines </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"examples/laneLines_thirdPass.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> This is the final desired result.</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the image to grayscale\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "# Function to apply the Canny transform\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "# Function to apply the gaussian blur\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# Function to obtain the vertices for the region of interest.\n",
    "def vertices(img):\n",
    "    x=img.shape[1]\n",
    "    y=img.shape[0]\n",
    "    LThres=50\n",
    "    T = 80 # parameter for edges of trapezium\n",
    "    vertices = np.array([[(LThres,y),(x/2-T, y/2+T), (x/2+T, y/2+T), (x-LThres,y)]], dtype=np.int32)\n",
    "    return vertices\n",
    "\n",
    "# Function to obtain the region of interest\n",
    "def region_of_interest(img, vertices):\n",
    "   \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n",
    "        \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope=((y2-y1)/(x2-x1)) \n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "# Modified function to interpolate the lines obtained            \n",
    "def draw_lines2(img, lines, color=[255, 0, 0], thickness=2):\n",
    "       \n",
    "    #algorithm logic:\n",
    "    #aim is to find x_min, y_min, x_max, y_max , slope and intercept for both lanes lines.\n",
    "    #for each line returned from the hough lines function:\n",
    "    #   calculate slope\n",
    "    #   calculate intercept\n",
    "    #   store positive and negative slope and intercept values separately in arrays.\n",
    "    #   y_min is the minimum of all the y coordinates.\n",
    "    #   y_max is the bottom of the image from where the lane lines start.\n",
    "    #   slope and intercept values for both lines are just the averages of all values stored previously.\n",
    "    #  x_min and x_max can now be calculated by fitting all the lines in the equation x = (y - intercept)/slope.\n",
    "    \n",
    "    #LINE DISPLAY PARAMETERS\n",
    "    color = [255, 0, 0]\n",
    "    thickness = 12\n",
    "    \n",
    "    #LINE PARAMETERS\n",
    "    SLOPE_THRESHOLD = 0.3\n",
    "    Y_MIN_ADJUST = 15\n",
    "    \n",
    "    positive_slopes = []\n",
    "    negative_slopes = []\n",
    "    \n",
    "    positive_intercepts = []\n",
    "    negative_intercepts = []\n",
    "    \n",
    "    #named as y_max despte being at the bottom corner of the image due to y axis in reverse direction\n",
    "    y_max = img.shape[0]\n",
    "    y_min = img.shape[0]\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            #calculate slope for the line\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            intercept = y2 - (slope*x2)\n",
    "            \n",
    "            #for negative slope\n",
    "            if slope < 0.0 and slope > -math.inf and abs(slope) > SLOPE_THRESHOLD:\n",
    "                #print('negative slope')\n",
    "                negative_slopes.append(slope)\n",
    "                negative_intercepts.append(intercept)\n",
    "                \n",
    "            #for positive slope\n",
    "            elif slope > 0.0 and slope < math.inf and abs(slope) > SLOPE_THRESHOLD:\n",
    "                #print('positive slope')\n",
    "                positive_slopes.append(slope)\n",
    "                positive_intercepts.append(intercept)\n",
    "            \n",
    "            y_min = min(y_min, y1, y2)\n",
    "    \n",
    "    y_min+=Y_MIN_ADJUST\n",
    "    \n",
    "    #get averages for positive and negative slopes\n",
    "    positive_slope_mean = np.mean(positive_slopes)\n",
    "    negative_slope_mean = np.mean(negative_slopes)\n",
    "\n",
    "    #get averages for potitive and negative intercepts\n",
    "    positive_intercept_mean = np.mean(positive_intercepts)\n",
    "    negative_intercept_mean = np.mean(negative_intercepts)\n",
    "    \n",
    "    #calculation of coordinates for lane for positive slopes\n",
    "    if len(positive_slopes) > 0:\n",
    "        x_max = int((y_max - positive_intercept_mean)/positive_slope_mean)\n",
    "        x_min = int((y_min - positive_intercept_mean)/positive_slope_mean)\n",
    "        cv2.line(img, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "    \n",
    "    #calculation of coordinates for lane for negative slopes\n",
    "    if len(negative_slopes) > 0:\n",
    "        x_max = int((y_max - negative_intercept_mean)/negative_slope_mean)\n",
    "        x_min = int((y_min - negative_intercept_mean)/negative_slope_mean)\n",
    "        cv2.line(img, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "\n",
    "        \n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n",
    "    slopes = [] \n",
    "    intercepts = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope=((y2-y1)/(x2-x1)) \n",
    "            slopes.append(slope)\n",
    "            intercept = y2 - (slope*x2)\n",
    "            intercepts.append(intercept)\n",
    "            \n",
    "    for index in range(0, len(slopes)-1):\n",
    "        totalSlope = slopes[i] + slopes[i+1] + slopes[i+2]\n",
    "        runningAvgSlope = totalSlope/3\n",
    "        \n",
    "        totalIntercept = slopes[i] + slopes[i+1] + slopes[i+2]\n",
    "        runningAvgIntercept = totalIntercept/3\n",
    "        \n",
    "        \n",
    "#  Returns an image with hough lines drawn.\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    # print(type(lines))\n",
    "    # print(lines.shape[::])\n",
    "    # print(lines[0])\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines2(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Function to produce weighted image of the original image and the lines obtained.\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of images for easy of use later.\n",
    "import os\n",
    "a=os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Lane Finding Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipeline that is explained above.\n",
    "def pipeline(img):\n",
    "    gray = grayscale(img)\n",
    "    gaus = gaussian_blur(gray,5)\n",
    "    c = canny(gaus, 120, 200)\n",
    "    roi=region_of_interest(c,vertices(img))\n",
    "    rho = 3            # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 40     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 70  # minimum number of pixels making up a line\n",
    "    max_line_gap = 100       \n",
    "    h = hough_lines(roi, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    final = weighted_img( h,img, α=0.8, β=1., γ=0.)\n",
    "    return final\n",
    "    \n",
    "    \n",
    "for i in range(6):\n",
    "    image = cv2.imread(\"test_images/\"+a[i])\n",
    "    final = pipeline(image)\n",
    "    cv2.imwrite(\"test_images_output/\"+a[i]+\".jpg\",final)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   9%|▉         | 20/221 [00:00<00:01, 197.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidWhiteRight.mp4\n",
      "CPU times: user 5.87 s, sys: 137 ms, total: 6.01 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/681 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidYellowLeft.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidYellowLeft.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidYellowLeft.mp4\n",
      "CPU times: user 18.9 s, sys: 645 ms, total: 19.5 s\n",
      "Wall time: 6.23 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(pipeline)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "The following video has sudden bright window where the detection of lanes using current algorithm is difficult. However using several other methods like playing with colorspaces etc. we can detect the lanes in this video quite easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/251 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/challenge.mp4.\n",
      "Moviepy - Writing video test_videos_output/challenge.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/challenge.mp4\n",
      "CPU times: user 9.84 s, sys: 464 ms, total: 10.3 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(pipeline)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
